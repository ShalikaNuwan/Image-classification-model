{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pytorch\n",
    "import torchvision\n",
    "import torchvision . transforms as transforms\n",
    "# Define data transformations ( optional , butrecommended )\n",
    "transform = transforms . Compose ([ transforms . ToTensor () ,transforms . Normalize ((0.5 , 0.5 , 0.5) , (0.5 , 0.5 ,0.5) ) ])\n",
    "# Load the training dataset\n",
    "\n",
    "    \n",
    "# train_dataset = torchvision . datasets . CIFAR10 ( root =r'D:\\semester 5\\Pattern recognition\\Assignment 3\\assignment 3', train = True , transform = transform , download =True )\n",
    "# # Load the testing dataset\n",
    "# test_dataset = torchvision . datasets . CIFAR10 ( root =r'D:\\semester 5\\Pattern recognition\\Assignment 3\\assignment 3 ', train = False , transform = transform , download =True )\n",
    "# # for keras\n",
    "from keras . datasets import cifar10\n",
    "# Load the CIFAR -10 dataset\n",
    "( train_images , train_labels ) , ( test_images ,test_labels ) = cifar10 . load_data ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "images = np.concatenate((train_images, test_images), axis=0)\n",
    "labels = np.concatenate((train_labels,test_labels),axis=0)\n",
    "\n",
    "number_of_train_images=int(images.shape[0]*0.6)\n",
    "number_of_test_images=int(images.shape[0]*0.2)\n",
    "number_of_validation_images=int(images.shape[0]*0.2)\n",
    "train_images,validation_images,test_images=np.split(images,[number_of_train_images,number_of_train_images+number_of_validation_images])\n",
    "train_labels,validation_labels,test_labels=np.split(labels,[number_of_train_images,number_of_train_images+number_of_validation_images])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the new input shape you want (e.g., (32, 32, 3))\n",
    "new_input_shape = (32, 32, 3)\n",
    "\n",
    "# Create a new input layer with the desired shape\n",
    "new_input = Input(shape=new_input_shape)\n",
    "\n",
    "# Load the pre-trained ResNet-50 model with the new input layer\n",
    "model = ResNet50(weights='imagenet', include_top=True, input_tensor=new_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model.fc = nn.Linear(in_features=64, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the last one (custom classifier)\n",
    "for layer in model.layers[:-1]:  \n",
    "    layer.trainable = False\n",
    "\n",
    "njs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 145s 127ms/step - loss: 1.9836 - accuracy: 0.4976 - val_loss: 1.3558 - val_accuracy: 0.5681\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 161s 143ms/step - loss: 1.2468 - accuracy: 0.6007 - val_loss: 1.3451 - val_accuracy: 0.5826\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 1.1692 - accuracy: 0.6196 - val_loss: 1.3647 - val_accuracy: 0.5826\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 1.1299 - accuracy: 0.6312 - val_loss: 1.4216 - val_accuracy: 0.5802\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 184s 163ms/step - loss: 1.1036 - accuracy: 0.6401 - val_loss: 1.4380 - val_accuracy: 0.5843\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 1.0873 - accuracy: 0.6445 - val_loss: 1.4656 - val_accuracy: 0.5908\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 175s 155ms/step - loss: 1.0709 - accuracy: 0.6509 - val_loss: 1.5571 - val_accuracy: 0.5692\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 169s 150ms/step - loss: 1.0555 - accuracy: 0.6542 - val_loss: 1.5209 - val_accuracy: 0.5812\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 161s 143ms/step - loss: 1.0487 - accuracy: 0.6565 - val_loss: 1.6086 - val_accuracy: 0.5663\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 159s 141ms/step - loss: 1.0370 - accuracy: 0.6587 - val_loss: 1.5345 - val_accuracy: 0.5813\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 1.0383 - accuracy: 0.6594"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, validation_data=(validation_images, validation_labels), epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
